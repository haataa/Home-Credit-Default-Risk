{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook focuse on using auto features to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import featuretools as ft\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and check basic info\n",
    "def read_check_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    #print('Training data shape: ', data.shape)\n",
    "    #print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>17473.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>33205.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>25128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>24709.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "48739      456221     NaN         Cash loans           F            N   \n",
       "48740      456222     NaN         Cash loans           F            N   \n",
       "48741      456223     NaN         Cash loans           F            Y   \n",
       "48742      456224     NaN         Cash loans           M            N   \n",
       "48743      456250     NaN         Cash loans           F            Y   \n",
       "\n",
       "      FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "48739               Y             0          121500.0    412560.0   \n",
       "48740               N             2          157500.0    622413.0   \n",
       "48741               Y             1          202500.0    315000.0   \n",
       "48742               N             0          225000.0    450000.0   \n",
       "48743               N             0          135000.0    312768.0   \n",
       "\n",
       "       AMT_ANNUITY             ...              FLAG_DOCUMENT_18  \\\n",
       "48739      17473.5             ...                             0   \n",
       "48740      31909.5             ...                             0   \n",
       "48741      33205.5             ...                             0   \n",
       "48742      25128.0             ...                             0   \n",
       "48743      24709.5             ...                             0   \n",
       "\n",
       "      FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "48739                0                0                0   \n",
       "48740                0                0                0   \n",
       "48741                0                0                0   \n",
       "48742                0                0                0   \n",
       "48743                0                0                0   \n",
       "\n",
       "      AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "48739                        0.0                       0.0   \n",
       "48740                        NaN                       NaN   \n",
       "48741                        0.0                       0.0   \n",
       "48742                        0.0                       0.0   \n",
       "48743                        0.0                       0.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "48739                         0.0                        0.0   \n",
       "48740                         NaN                        NaN   \n",
       "48741                         0.0                        0.0   \n",
       "48742                         0.0                        0.0   \n",
       "48743                         0.0                        0.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "48739                        0.0                         1.0  \n",
       "48740                        NaN                         NaN  \n",
       "48741                        3.0                         1.0  \n",
       "48742                        0.0                         2.0  \n",
       "48743                        1.0                         4.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in train and test file and combine them\n",
    "app_train = read_check_data(\"./data/application_train.csv\")\n",
    "app_test = read_check_data(\"./data/application_test.csv\")\n",
    "app = app_train.append(app_test,sort=False)\n",
    "del app_train, app_test\n",
    "app.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df, categorical_columns=None):\n",
    "    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n",
    "    # if categorical_colunms are not given than treat object as categorical features\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 4 people code_gender value 'XNA'\n",
    "app = app[app['CODE_GENDER'] != 'XNA']  # 4 people with XNA code gender\n",
    "app['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "app['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "# change all categorical feature to numerical \n",
    "app_clean, categorical_columns = label_encoder(app, categorical_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df_child, parent_var, df_col_name):\n",
    "    \"\"\"\n",
    "    Groups and aggregates the numeric values in a child dataframe\n",
    "    by the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df_child (dataframe): \n",
    "            the child dataframe to calculate the statistics on\n",
    "        parent_var (string): \n",
    "            the parent variable used for grouping and aggregating\n",
    "        df_col_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated by the `parent_var` for \n",
    "            all numeric columns. The aggregate function are 'count', 'mean', 'max', 'min', 'sum'\n",
    "            Each observation of the parent variable will have \n",
    "            one row in the dataframe with the parent variable as the index. \n",
    "            The columns are also renamed using the `df_col_name`. Columns with all duplicate\n",
    "            values are removed. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove id variables other than grouping variable\n",
    "    # e.g. SK_ID_BUREAU\n",
    "    for col in df_child:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df_child = df_child.drop(columns = col)\n",
    "            \n",
    "    # Only want the numeric variables\n",
    "    parent_ids = df_child[parent_var].copy()\n",
    "    numeric_df = df_child.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = []\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_col_name, var, stat))\n",
    "    \n",
    "    agg.columns = columns\n",
    "    \n",
    "    # Remove the columns with all redundant values\n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_categorical(df, parent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregates the categorical features in a child dataframe\n",
    "    for each observation of the parent variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    parent_var : string\n",
    "        The variable by which to group and aggregate the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with aggregated statistics for each observation of the parent_var\n",
    "        The columns are also renamed and columns with duplicate values are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    # Remove duplicate columns by values\n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory management\n",
    "def agg_grandchild(df, parent_df, parent_var, grandparent_var, df_name):\n",
    "    \"\"\"\n",
    "    Aggregate a grandchild dataframe at the grandparent level.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df : dataframe\n",
    "            Data with each row representing one observation\n",
    "            \n",
    "        parent_df : dataframe\n",
    "            Parent table of df that must have the parent_var and \n",
    "            the grandparent_var. Used only to get the grandparent_var into\n",
    "            the dataframe after aggregations\n",
    "            \n",
    "        parent_var : string\n",
    "            Variable representing each unique observation in the parent.\n",
    "            For example, `SK_ID_BUREAU` or `SK_ID_PREV`\n",
    "            \n",
    "        grandparent_var : string\n",
    "            Variable representing each unique observation in the grandparent.\n",
    "            For example, `SK_ID_CURR`. \n",
    "            \n",
    "        df_name : string\n",
    "            String for renaming the resulting columns.\n",
    "            The columns are name with the `df_name` and with the \n",
    "            statistic calculated in the column\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "        df_info : dataframe\n",
    "            A dataframe with one row for each observation of the grandparent variable.\n",
    "            The grandparent variable forms the index, and the resulting dataframe\n",
    "            can be merged with the grandparent to be used for training/testing. \n",
    "            Columns with all duplicate values are removed from the dataframe before returning.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # set the parent_var as the index of the parent_df for faster merges\n",
    "    parent_df = parent_df[[parent_var, grandparent_var]].copy().set_index(parent_var)\n",
    "    \n",
    "    # Aggregate the numeric variables at the parent level\n",
    "    df_agg = agg_numeric(df, parent_var, '%s_LOAN' % df_name)\n",
    "    \n",
    "    # Merge to get the grandparent variable in the data\n",
    "    df_agg = df_agg.merge(parent_df, \n",
    "                          on = parent_var, how = 'left')\n",
    "    \n",
    "    # Aggregate the numeric variables at the grandparent level\n",
    "    df_agg_client = agg_numeric(df_agg, grandparent_var, '%s_CLIENT' % df_name)\n",
    "    \n",
    "    # Can only apply one-hot encoding to categorical variables\n",
    "    if any(df.dtypes == 'object'):\n",
    "    \n",
    "        # Aggregate the categorical variables at the parent level\n",
    "        df_agg_cat = agg_categorical(df, parent_var, '%s_LOAN' % df_name)\n",
    "        df_agg_cat = df_agg_cat.merge(parent_df,\n",
    "                                      on = parent_var, how = 'left')\n",
    "\n",
    "        # Aggregate the categorical variables at the grandparent level\n",
    "        df_agg_cat_client = agg_numeric(df_agg_cat, grandparent_var, '%s_CLIENT' % df_name)\n",
    "        df_info = df_agg_client.merge(df_agg_cat_client, on = grandparent_var, how = 'outer')\n",
    "        \n",
    "        gc.enable()\n",
    "        del df_agg, df_agg_client, df_agg_cat, df_agg_cat_client\n",
    "        gc.collect()\n",
    "    \n",
    "    # If there are no categorical variables, then we only need the numeric aggregations\n",
    "    else:\n",
    "        df_info = df_agg_client.copy()\n",
    "    \n",
    "        gc.enable()\n",
    "        del df_agg, df_agg_client\n",
    "        gc.collect()\n",
    "    \n",
    "    # Drop the columns with all duplicated values\n",
    "    _, idx = np.unique(df_info, axis = 1, return_index=True)\n",
    "    df_info = df_info.iloc[:, idx]\n",
    "    \n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(train):\n",
    "    \"\"\"Compute cross validation ROC AUC of a gradient boosting model for a given training dataset\"\"\"\n",
    "    \n",
    "    # Extract the labels\n",
    "    train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "    train = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "\n",
    "    # Create a  lgb training set\n",
    "    train_set = lgb.Dataset(train, label = train_labels)\n",
    "\n",
    "    # Find default hyperparameters\n",
    "    model = lgb.LGBMClassifier()\n",
    "    params = model.get_params()\n",
    "\n",
    "    # Number of estimators will be selected through early stopping\n",
    "    del params['n_estimators'], params['silent']\n",
    "\n",
    "    # Early stoppping with 5 fold cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, metrics = 'auc', \n",
    "                        early_stopping_rounds = 100, seed = RSEED, nfold = 5)\n",
    "\n",
    "    print('Cross Validation ROC AUC: {:.5f} with std: {:.5f}.'.format(cv_results['auc-mean'][-1],\n",
    "                                                                               cv_results['auc-stdv'][-1]))\n",
    "\n",
    "    print('Number of estimators trained: {}'.format(len(cv_results['auc-mean'])))\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cv_results, train):\n",
    "     # Extract the labels\n",
    "    train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "    train = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "    \n",
    "    # Make model with optimal number of estimators and train on training data\n",
    "    model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), random_state=RSEED)\n",
    "    model.fit(train, train_labels)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model,train):\n",
    "    fi = pd.DataFrame({'feature': train.drop(columns = ['TARGET', 'SK_ID_CURR']).columns, \n",
    "                   'importance': model.feature_importances_})\n",
    "    fi = fi.sort_values('importance', ascending = False)\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, test):\n",
    "    \"\"\"Make a submission dataframe for the Kaggle competition for a given dataset.\"\"\"\n",
    "    \n",
    "    # Extract the labels\n",
    "    test_ids = list(test['SK_ID_CURR'])\n",
    "    test = test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "     \n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict_proba(test)[:, 1]\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, \n",
    "                                'TARGET': preds})\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(features,sub_filename):\n",
    "    features_train_temp = features[features['TARGET'].notnull()]\n",
    "    features_test_temp = features[features['TARGET'].isnull()]\n",
    "    del features\n",
    "    cv_results_temp = cross_validate(features_train_temp)\n",
    "    model_temp = get_model(cv_results_temp, features_train_temp)\n",
    "    \n",
    "    fi_temp = get_feature_importance(model_temp,features_train_temp)\n",
    "    fi_unimportant = fi_temp[fi_temp['importance'] < 5]\n",
    "    \n",
    "    features_train = features_train_temp.drop(np.array(fi_unimportant['feature']), axis=1)\n",
    "    features_test = features_test_temp.drop(np.array(fi_unimportant['feature']), axis=1)\n",
    "    del features_train_temp\n",
    "    del features_test_temp\n",
    "    \n",
    "    cv_results = cross_validate(features_train)\n",
    "    model = get_model(cv_results, features_train)\n",
    "    submission = make_submission(model, features_test)\n",
    "    submission.to_csv(sub_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ratios_features(df):\n",
    "    df['BUREAU_INCOME_CREDIT_RATIO'] = df['BUREAU_AMT_CREDIT_SUM_mean'] / df['AMT_INCOME_TOTAL']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bureau_feat(df):\n",
    "    #add hand-design features for bureau data\n",
    "    df['CREDIT_DURATION'] = -df['DAYS_CREDIT'] + df['DAYS_CREDIT_ENDDATE']\n",
    "    df['ENDDATE_DIF'] = df['DAYS_CREDIT_ENDDATE'] - df['DAYS_ENDDATE_FACT']\n",
    "    # Credit to debt ratio and difference\n",
    "    df['DEBT_PERCENTAGE'] = df['AMT_CREDIT_SUM'] / df['AMT_CREDIT_SUM_DEBT']\n",
    "    df['DEBT_CREDIT_DIFF'] = df['AMT_CREDIT_SUM'] - df['AMT_CREDIT_SUM_DEBT']\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT_SUM'] / df['AMT_ANNUITY']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_feat(df):\n",
    "    # Feature engineering: ratios and difference\n",
    "    df['APPLICATION_CREDIT_DIFF'] = df['AMT_APPLICATION'] - df['AMT_CREDIT']\n",
    "    df['APPLICATION_CREDIT_RATIO'] = df['AMT_APPLICATION'] / df['AMT_CREDIT']\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT']/df['AMT_ANNUITY']\n",
    "    df['DOWN_PAYMENT_TO_CREDIT'] = df['AMT_DOWN_PAYMENT'] / df['AMT_CREDIT']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and make auto features\n",
    "bureau = read_check_data(\"./data/bureau.csv\")\n",
    "bureau = get_bureau_feat(bureau)\n",
    "bureau_agg = agg_numeric(bureau, 'SK_ID_CURR', 'BUREAU')\n",
    "bureau_categorical = agg_categorical(bureau, 'SK_ID_CURR', 'BUREAU')\n",
    "\n",
    "previous_application = read_check_data(\"./data/previous_application.csv\")\n",
    "previous_application = get_previous_feat(previous_application)\n",
    "previous_agg = agg_numeric(previous_application, 'SK_ID_CURR', 'previous')\n",
    "previous_categorical = agg_categorical(previous_application, 'SK_ID_CURR', 'PREVIOUS')\n",
    "\n",
    "bureau_balance = read_check_data(\"./data/bureau_balance.csv\")\n",
    "bureau_balance_results = agg_grandchild(bureau_balance, bureau, \n",
    "                                        'SK_ID_BUREAU', 'SK_ID_CURR', 'BB')\n",
    "del bureau_balance\n",
    "\n",
    "credit_card = read_check_data('./data/credit_card_balance.csv')\n",
    "credit_card_info = agg_grandchild(credit_card, previous_application,\n",
    "                                  'SK_ID_PREV', 'SK_ID_CURR', 'CC')\n",
    "del credit_card\n",
    "\n",
    "cash = read_check_data('./data/POS_CASH_balance.csv')\n",
    "cash_info = agg_grandchild(cash, previous_application, \n",
    "                           'SK_ID_PREV', 'SK_ID_CURR', 'CASH')\n",
    "del cash\n",
    "\n",
    "installments = read_check_data('./data/installments_payments.csv')\n",
    "installments_info = agg_grandchild(installments, previous_application,\n",
    "                                   'SK_ID_PREV', 'SK_ID_CURR', 'IN')\n",
    "del installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356251, 1340)\n"
     ]
    }
   ],
   "source": [
    "# Merge features\n",
    "app = pd.merge(app_clean,bureau_agg,on='SK_ID_CURR',how='left')\n",
    "del bureau_agg,app_clean\n",
    "app = pd.merge(app,bureau_categorical,on='SK_ID_CURR',how='left')\n",
    "del bureau_categorical\n",
    "app = pd.merge(app,previous_agg,on='SK_ID_CURR',how='left')\n",
    "del previous_agg\n",
    "app = pd.merge(app,previous_categorical,on='SK_ID_CURR',how='left')\n",
    "del previous_categorical\n",
    "app = pd.merge(app,bureau_balance_results,on='SK_ID_CURR',how='left')\n",
    "del bureau_balance_results\n",
    "app = pd.merge(app,credit_card_info,on='SK_ID_CURR',how='left')\n",
    "del credit_card_info\n",
    "app = pd.merge(app,cash_info,on='SK_ID_CURR',how='left')\n",
    "del cash_info\n",
    "app = pd.merge(app,installments_info,on='SK_ID_CURR',how='left')\n",
    "del installments_info\n",
    "\n",
    "print(app.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation ROC AUC: 0.77766 with std: 0.00301.\n",
      "Number of estimators trained: 184\n",
      "Cross Validation ROC AUC: 0.77873 with std: 0.00239.\n",
      "Number of estimators trained: 171\n"
     ]
    }
   ],
   "source": [
    "get_submission(app,'./data/submission_nighth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
